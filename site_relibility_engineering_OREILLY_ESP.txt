Prólogo

La historia de Google es una historia de crecimiento. Es una de las grandes historias de éxito de la industria informática, que marca un cambio hacia un negocio centrado en TI. Google fue una de las primeras empresas en definir lo que significaba la alineación entre negocios y TI en la práctica, y posteriormente informó el concepto de DevOps para una comunidad de TI más amplia. Este libro ha sido escrito por un amplio grupo de personas que hicieron que esa transición se convirtiera en realidad.

Google creció en un momento en que el papel tradicional del administrador de sistemas estaba siendo transformado. Cuestionó la administración de sistemas, como si dijera: no podemos permitirnos seguir la tradición como autoridad, tenemos que pensar de nuevo y no tenemos tiempo para esperar a que todos los demás se pongan al día. En la introducción a Principios de administración de redes y sistemas [Bur99], afirmé que la administración de sistemas era una forma de ingeniería humana-computadora. Esto fue rechazado enérgicamente por algunos revisores, que dijeron "todavía no estamos en la etapa en que podemos llamarlo ingeniería". En ese momento, sentí que el campo se había perdido, atrapado en su propia cultura de magos, y no podía ver una forma de avanzar. Luego, Google dibujó una línea en el silicio, forzando que ese destino se convirtiera en realidad. El papel revisado se llamó SRE, o Ingeniero de Confiabilidad del Sitio. Algunos de mis amigos estuvieron entre los primeros de esta nueva generación de ingenieros; lo formalizaron utilizando software y automatización. Inicialmente, eran muy secretos, y lo que sucedió dentro y fuera de Google era muy diferente: la experiencia de Google era única. Con el tiempo, la información y los métodos han fluido en ambas direcciones. Este libro muestra una voluntad de dejar que el pensamiento SRE salga de las sombras.

Aquí, no solo vemos cómo Google construyó su legendaria infraestructura, sino también cómo estudió, aprendió y cambió de opinión sobre las herramientas y las tecnologías en el camino. También nosotros podemos enfrentar desafíos abrumadores con un espíritu abierto. La naturaleza tribal de la cultura de TI a menudo atrapa a los practicantes en posiciones dogmáticas que frenan a la industria. Si Google superó esta inercia, también podemos hacerlo.

Este libro es una colección de ensayos de una sola empresa, con una visión común. El hecho de que las contribuciones estén alineadas en torno a un objetivo común de la empresa es lo que lo hace especial. Hay temas comunes y personajes comunes (sistemas de software) que reaparecen en varios capítulos. Vemos opciones de Diferentes perspectivas, y sabemos que se correlacionan para resolver intereses en competencia. Los artículos no son piezas rigurosas y académicas; son relatos personales, escritos con orgullo, en una variedad de estilos personales y desde la perspectiva de habilidades individuales. Están escritos con valentía y con una honestidad intelectual que es refrescante y poco común en la literatura industrial. Algunos afirman "nunca hagas esto, siempre haz aquello", otros son más filosóficos y tentativos, reflejando la variedad de personalidades dentro de una cultura de TI, y cómo eso también juega un papel en la historia. Nosotros, a su vez, los leemos con la humildad de observadores que no fueron parte del viaje y no tienen toda la información sobre los numerosos desafíos en conflicto. Nuestras muchas preguntas son el verdadero legado del volumen: ¿Por qué no hicieron X? ¿Qué pasaría si hubieran hecho Y? ¿Cómo miraremos hacia atrás en esto en el futuro? Es comparando nuestras propias ideas con la lógica aquí que podemos medir nuestros propios pensamientos y experiencias.

Lo más impresionante de todo sobre este libro es su mera existencia. Hoy en día, escuchamos una cultura descarada de "solo muéstrame el código". Una cultura de "no hagas preguntas" ha crecido alrededor del código abierto, donde la comunidad en lugar de la experiencia es la campeona. Google es una empresa que se atrevió a pensar en los problemas desde principios fundamentales y a emplear a los mejores talentos con una gran proporción de doctorados. Las herramientas eran solo componentes en procesos, trabajando junto con cadenas de software, personas y datos. Nada aquí nos dice cómo resolver problemas universalmente, pero ese es el punto. Historias como estas son mucho más valiosas que el código o diseños que resultaron en ellas. Las implementaciones son efímeras, pero la lógica documentada es invaluable. Rara vez tenemos acceso a este tipo de información.

Este, entonces, es el relato de cómo una empresa lo hizo. El hecho de que sea muchas historias superpuestas nos muestra que escalar es mucho más que solo una ampliación fotográfica de una arquitectura de computadora de texto. Se trata de escalar un proceso empresarial, en lugar de solo la maquinaria. Esta lección sola vale su peso en papel electrónico.

No nos involucramos mucho en la revisión crítica de nosotros mismos en el mundo de la TI; como tal, hay mucha reinvención y repetición. Durante muchos años, solo había la comunidad de la conferencia USENIX LISA discutiendo la infraestructura de TI, más algunas conferencias sobre sistemas operativos. Hoy en día es muy diferente, sin embargo, este libro todavía se siente como una oferta rara: una documentación detallada del paso de Google a través de una época decisiva. La historia no es para copiar— aunque tal vez para emular— pero puede inspirar el próximo paso para todos nosotros. Hay una honestidad intelectual única en estas páginas, expresando tanto liderazgo como humildad. Estas son historias de esperanzas, miedos, éxitos y fracasos. Saludo el coraje de los autores y editores al permitir tal candor, para que nosotros, que no somos parte de las experiencias prácticas, también podamos beneficiarnos de las lecciones aprendidas dentro del capullo.

Mark Burgess


Prefacio

La ingeniería de software tiene esto en común con tener hijos: el trabajo antes del nacimiento es doloroso y difícil, pero el trabajo después del nacimiento es donde se invierte la mayor parte del esfuerzo. Sin embargo, la ingeniería de software como disciplina dedica mucho más tiempo a hablar sobre el primer período en lugar del segundo, a pesar de que se estima que el 40-90% de los costos totales de un sistema se incurren después del nacimiento. El modelo popular de la industria que concibe el software desplegado y operativo como "estabilizado" en producción y, por lo tanto, necesitando mucha menos atención de los ingenieros de software, es incorrecto. A través de esta lente, vemos que si la ingeniería de software tiende a enfocarse en diseñar y construir sistemas de software, debe haber otra disciplina que se enfoque en todo el ciclo de vida de los objetos de software, desde la concepción hasta la descomisión pacífica. Esta disciplina utiliza - y necesita utilizar - una amplia gama de habilidades, pero tiene preocupaciones separadas de otros tipos de ingenieros. Hoy en día, nuestra respuesta es la disciplina que Google llama Ingeniería de Confiabilidad del Sitio (SRE).

Entonces, ¿qué es exactamente la Ingeniería de Confiabilidad del Sitio (SRE)? Admitimos que no es un nombre particularmente claro para lo que hacemos - casi todos los ingenieros de confiabilidad del sitio en Google se les pregunta qué es exactamente eso y qué hacen en realidad, con regularidad.

Desempaquetando el término un poco, primero y principalmente, los SRE son ingenieros. Aplicamos los principios de la ciencia de la computación y la ingeniería al diseño y desarrollo de sistemas de cómputo: generalmente, grandes y distribuidos. A veces, nuestra tarea es escribir el software para esos sistemas junto con nuestros compañeros de desarrollo de productos; a veces, nuestra tarea es construir todas las piezas adicionales que esos sistemas necesitan, como copias de seguridad o equilibrio de carga, idealmente para que puedan ser reutilizadas en sistemas; y a veces, nuestra tarea es descubrir cómo aplicar soluciones existentes a nuevos problemas.

A continuación, nos enfocamos en la confiabilidad del sistema. Ben Treynor Sloss, vicepresidente de Google para operaciones 24/7, originador del término SRE, afirma que la confiabilidad es la característica más fundamental de cualquier producto: un sistema no es muy útil si nadie puede usarlo. Debido a que la confiabilidad es tan crítica, los SRE se enfocan en encontrar formas de mejorar el diseño y la operación de los sistemas para hacerlos más escalables, más confiables y más eficientes. Sin embargo, solo invertimos esfuerzo en esta dirección hasta cierto punto: cuando los sistemas son "lo suficientemente confiables", invertimos nuestros esfuerzos en agregar características o construir nuevos productos.

Finalmente, los SRE se enfocan en operar servicios construidos sobre nuestros sistemas de cómputo distribuidos, ya sean servicios de almacenamiento a escala planetaria, correo electrónico para cientos de millones de usuarios o donde Google comenzó, la búsqueda web. El "sitio" en nuestro nombre originalmente se refería al papel de SRE en mantener el sitio web google.com en funcionamiento, aunque ahora ejecutamos muchos más servicios, muchos de los cuales no son sitios web - desde infraestructura interna como Bigtable hasta productos para desarrolladores externos como la plataforma Google Cloud.

Aunque hemos representado a SRE como una disciplina amplia, no es sorprendente que haya surgido en el mundo en constante movimiento de los servicios web, y tal vez en su origen deba algo a las peculiaridades de nuestra infraestructura. Es igualmente no sorprendente que de todas las características post-despliegue del software que podríamos elegir para dedicar atención especial, la confiabilidad sea la que consideramos primaria.

A pesar de surgir en Google y en la comunidad de servicios web en general, creemos que esta disciplina tiene lecciones aplicables a otras comunidades y organizaciones. Este libro es un intento de explicar cómo hacemos las cosas: tanto para que otras organizaciones puedan aprovechar lo que hemos aprendido, como para que podamos definir mejor el papel y lo que significa el término. Con ese fin, hemos organizado el libro para que los principios generales y las prácticas más específicas Para ese fin, hemos organizado el libro de manera que los principios generales y las prácticas más específicas estén separados cuando sea posible, y cuando sea apropiado discutir un tema particular con información específica de Google, confiamos en que el lector nos permitirá hacerlo y no tendrá miedo de sacar conclusiones útiles sobre su propio entorno.

También hemos proporcionado algunos materiales de orientación - una descripción del entorno de producción de Google y un mapa entre algunos de nuestros software internos y software público - que deberían ayudar a contextualizar lo que estamos diciendo y hacerlo más directamente utilizable.

En última instancia, por supuesto, un software y una ingeniería de sistemas más orientados a la confiabilidad son inherentemente buenos. Sin embargo, reconocemos que las organizaciones más pequeñas pueden estar preguntándose cómo pueden aprovechar al máximo la experiencia representada aquí: al igual que la seguridad, cuanto antes se preocupe por la confiabilidad, mejor. Esto implica que aunque una organización pequeña tenga muchas preocupaciones urgentes y las opciones de software que tome pueden diferir de las que tomó Google, todavía vale la pena implementar un soporte de confiabilidad ligero desde el principio, porque es menos costoso ampliar una estructura más adelante que introducir una que no está presente. La gestión contiene un número de mejores prácticas para la formación, la comunicación y las reuniones que hemos encontrado que funcionan bien para nosotros, muchas de las cuales deberían ser inmediatamente utilizables por su organización.

Pero para tamaños entre una startup y una multinacional, probablemente ya hay alguien en su organización que está haciendo trabajo de SRE, sin que necesariamente se llame así o se reconozca como tal. Otra forma de comenzar a mejorar la confiabilidad para su organización es reconocer formalmente ese trabajo, o encontrar a esas personas y fomentar lo que hacen - recompensarlo. Son personas que se encuentran en la encrucijada entre una forma de ver el mundo y otra: como Newton, que a veces se llama no el primer físico del mundo, sino el último alquimista.

Y tomando la vista histórica, ¿quién, entonces, mirando hacia atrás, podría ser el primer SRE? Nos gusta pensar que Margaret Hamilton, trabajando en el programa Apolo en préstamo de MIT, tenía todos los rasgos significativos del primer SRE. En sus propias palabras, "parte de la cultura era aprender de todos y de todo, incluyendo de lo que menos se esperaría".

Un caso en punto fue cuando su joven hija Lauren vino a trabajar con ella un día, mientras algunos del equipo estaban ejecutando escenarios de misión en la computadora de simulación híbrida. Como los niños pequeños hacen, Lauren se fue explorando y causó que una "misión" se estrellara al seleccionar las teclas DSKY de una manera inesperada, alertando al equipo sobre lo que sucedería si el programa de prelanzamiento, P01, fuera seleccionado inadvertidamente por un astronauta real durante una misión real, durante el curso real. (Lanzar P01 inadvertidamente en una misión real sería un problema mayor, porque borra los datos de navegación, y la computadora no estaba equipada para pilotar la nave con datos de navegación inexistentes).

Con los instintos de un SRE, Margaret presentó una solicitud de cambio de programa para agregar un código de verificación de errores especial en el software de vuelo a bordo en caso de que un astronauta seleccionara P01 inadvertidamente durante una misión real. Pero este movimiento fue considerado innecesario por los "superiores" de la NASA: ¡por supuesto, eso nunca podría suceder! Entonces, en lugar de agregar un código de verificación de errores, Margaret actualizó la documentación de las especificaciones de la misión para decir lo equivalente a "No seleccione P01 durante el vuelo". (Al parecer, la actualización fue divertida para muchos en el proyecto, quienes habían sido informados muchas veces de que los astronautas no cometerían errores - después de todo, habían sido entrenados para ser perfectos).

Bueno, la salvaguarda sugerida por Margaret solo fue considerada innecesaria hasta la siguiente misión, en el Apolo 8, justo días después de la actualización de las especificaciones. Durante el curso medio del cuarto día de vuelo con los astronautas Jim Lovell, William Anders y Frank Borman a bordo, Jim Lovell seleccionó P01 por error - como sucede, en Navidad - creando mucha confusión para todos los involucrados. Este fue un problema crítico, porque en ausencia de una solución alternativa, no había datos de navegación, lo que significaba que los astronautas nunca regresarían a casa. Afortunadamente, la actualización de la documentación había llamado explícitamente a esta posibilidad, y fue invaluable para averiguar cómo subir datos útiles y recuperar la misión, con poco tiempo que perder.

Como dice Margaret, "una comprensión exhaustiva de cómo operar los sistemas no fue suficiente para prevenir errores humanos", y la solicitud de cambio para agregar software de detección y recuperación de errores al programa de prelanzamiento P01 fue aprobada poco después.

Aunque el incidente del Apolo 8 ocurrió hace décadas, hay mucho en los párrafos anteriores directamente relevante para la vida de los ingenieros hoy en día, y mucho que seguirá siendo directamente relevante en el futuro. Por lo tanto, para los sistemas que cuidan, para los grupos en los que trabajan o para las organizaciones que están construyendo, por favor, tengan en cuenta el Camino SRE: la exhaustividad y la dedicación, la creencia en el valor de la preparación y la documentación, y la conciencia de lo que podría salir mal, junto con un fuerte deseo de prevenirlo. ¡Bienvenidos a nuestra profesión emergente!

Este libro es una serie de ensayos escritos por miembros y ex miembros de la organización de Ingeniería de Confiabilidad del Sitio (SRE) de Google. Es más similar a las actas de una conferencia que a un libro estándar escrito por un autor o un pequeño número de autores. Cada capítulo está diseñado para ser leído como parte de un todo coherente, pero se puede obtener mucho leyendo sobre cualquier tema que te interese en particular. (Si hay otros artículos que apoyan o informan el texto, los citamos para que puedas seguir adelante).

No necesitas leer en un orden particular, aunque sugerimos al menos comenzar con los capítulos "El entorno de producción en Google, desde la perspectiva de un SRE" y "Aceptando el riesgo", que describen el entorno de producción de Google y esbozan cómo SRE aborda el riesgo, respectivamente. (El riesgo es, en muchos sentidos, la calidad clave de nuestra profesión). Leer de principio a fin es, por supuesto, también útil y posible; nuestros capítulos están agrupados temáticamente en Principios, Prácticas y Gestión. Cada uno tiene una pequeña introducción que destaca de qué tratan las piezas individuales y hace referencia a otros artículos publicados por SREs de Google, que cubren temas específicos en más detalle. Además, el sitio web complementario de este libro, https://g.co/SREBook, tiene una serie de recursos útiles.

Esperamos que esto sea al menos tan útil e interesante para ti como lo fue para nosotros reunirlo.

— Los editores


Parte I - Introducción

Esta sección proporciona algunas orientaciones generales sobre qué es SRE y por qué es diferente de las prácticas más convencionales de la industria de TI.

Ben Treynor Sloss, el vicepresidente senior que supervisa las operaciones técnicas en Google - y el originador del término "Ingeniería de Confiabilidad del Sitio" (SRE) - proporciona su visión sobre qué significa SRE, cómo funciona y cómo se compara con otras formas de hacer las cosas en la industria, en la Introducción.

Proporcionamos una guía sobre el entorno de producción en Google en El entorno de producción en Google, desde la perspectiva de un SRE, como una forma de ayudarte a familiarizarte con la gran cantidad de nuevos términos y sistemas que vas a conocer en el resto del libro.

Capítulo 1 - Introducción

En este capítulo, Ben Treynor Sloss presenta su visión sobre qué es SRE y cómo funciona. También compara SRE con otras formas de hacer las cosas en la industria de TI y explica por qué SRE es diferente.

El capítulo comienza con una definición de SRE y una explicación de cómo se originó el término. Luego, Treynor Sloss describe los principios clave de SRE, incluyendo la importancia de la confiabilidad, la escalabilidad y la eficiencia.

También se discute la relación entre SRE y la ingeniería de software, y cómo SRE se enfoca en la operación y el mantenimiento de los sistemas en lugar de solo en su desarrollo. Treynor Sloss también destaca la importancia de la colaboración y la comunicación entre los equipos de SRE y otros equipos en la organización.

Finalmente, el capítulo concluye con una discusión sobre los beneficios de SRE y cómo puede ayudar a las organizaciones a mejorar la confiabilidad y la eficiencia de sus sistemas.

Capítulo 1 - Introducción

Escrito por Benjamin Treynor Sloss
Editado por Betsy Beyer

La esperanza no es una estrategia.
Dicho tradicional de SRE

Es una verdad universalmente reconocida que los sistemas no se ejecutan solos. ¿Cómo, entonces, debería ejecutarse un sistema, particularmente un sistema de cómputo complejo que opera a gran escala?

El enfoque de Sysadmin para la gestión de servicios
Históricamente, las empresas han empleado administradores de sistemas para ejecutar sistemas de cómputo complejos.

Este enfoque de administrador de sistemas, o sysadmin, implica ensamblar componentes de software existentes y desplegarlos para que trabajen juntos para producir un servicio. Los sysadmins luego son responsables de ejecutar el servicio y responder a eventos y actualizaciones a medida que ocurren. A medida que el sistema crece en complejidad y volumen de tráfico, generando un aumento correspondiente en eventos y actualizaciones, el equipo de sysadmins crece para absorber el trabajo adicional. Debido a que el papel de sysadmin requiere un conjunto de habilidades muy diferente al de los desarrolladores de productos, los desarrolladores y los sysadmins están divididos en equipos discretos: "desarrollo" y "operaciones" o "ops".

El modelo de gestión de servicios de sysadmin tiene varias ventajas. Para las empresas que deciden cómo ejecutar y dotar de personal a un servicio, este enfoque es relativamente fácil de implementar: como un paradigma industrial familiar, hay muchos ejemplos de los que aprender y emular. Hay un talento disponible en todo el mundo. Hay una variedad de herramientas, componentes de software (de estantería o no) y empresas de integración disponibles para ayudar a ejecutar esos sistemas ensamblados, por lo que un equipo de sysadmins novatos no tiene que reinventar la rueda y diseñar un sistema desde cero.

El enfoque de sysadmin y la división de desarrollo/ops que lo acompaña tienen una serie de desventajas y trampas. Estas se dividen en dos categorías: costos directos e indirectos.

Los costos directos no son sutiles ni ambiguos. Ejecutar un servicio con un equipo que depende de la intervención manual para la gestión de cambios y el manejo de eventos se vuelve caro a medida que el servicio y/o el tráfico al servicio crecen, porque el tamaño del equipo debe escalar con la carga generada por el sistema.

Los costos indirectos de la división de desarrollo/ops pueden ser sutiles, pero a menudo son más costosos para la organización que los costos directos. Estos costos surgen del hecho de que los dos equipos son muy diferentes en antecedentes, habilidades y incentivos. Utilizan un vocabulario diferente para describir situaciones; llevan diferentes suposiciones sobre riesgos y posibilidades de soluciones técnicas; tienen diferentes suposiciones sobre el nivel de estabilidad del producto objetivo. La división entre los grupos puede fácilmente convertirse en una de no solo incentivos, sino también comunicación, objetivos y eventualmente, confianza y respeto. Este resultado es una patología.

Los equipos de operaciones tradicionales y sus contrapartes en el desarrollo de productos a menudo terminan en conflicto, más visible sobre cuán rápido se puede lanzar software a producción. En su núcleo, los equipos de desarrollo quieren lanzar nuevas características y verlas adoptadas por los usuarios. En su núcleo, los equipos de operaciones quieren asegurarse de que el servicio no se rompa mientras están sujetando la página. Debido a que la mayoría de las interrupciones son causadas por algún tipo de cambio, un lanzamiento de características nuevo, un lanzamiento de configuración nuevo o un tipo nuevo de tráfico de usuarios, los objetivos de los dos equipos están fundamentalmente en tensión.

Ambos grupos entienden que es inaceptable expresar sus intereses en los términos más brutales posibles ("Queremos lanzar cualquier cosa, en cualquier momento, sin obstáculos" versus "No queremos cambiar nada en el sistema una vez que funciona"). Y porque su vocabulario y suposiciones de riesgo difieren, ambos grupos a menudo recurren a una forma familiar de guerra de trincheras para avanzar en sus intereses. El equipo de operaciones intenta salvaguardar el sistema en ejecución contra el riesgo de cambio introduciendo puertas de lanzamiento y cambio. Por El conflicto no es una parte inevitable de ofrecer un servicio de software. Google ha elegido ejecutar nuestros sistemas con un enfoque diferente: nuestros equipos de Ingeniería de Confiabilidad del Sitio (SRE) se centran en contratar ingenieros de software para ejecutar nuestros productos y crear sistemas para realizar el trabajo que normalmente sería realizado, a menudo de manera manual, por administradores de sistemas.

¿Qué es exactamente la Ingeniería de Confiabilidad del Sitio, como se ha definido en Google? Mi explicación es simple: SRE es lo que sucede cuando se le pide a un ingeniero de software que diseñe un equipo de operaciones. Cuando me uní a Google en 2003 y me encargué de ejecutar un "Equipo de Producción" de siete ingenieros, toda mi vida hasta ese momento había sido ingeniería de software. Así que diseñé y gestioné el grupo de la manera en que querría que funcionara si yo mismo trabajara como SRE. Ese grupo ha madurado desde entonces para convertirse en el equipo de SRE de Google actual, que sigue siendo fiel a sus orígenes como lo imaginó un ingeniero de software de toda la vida.

Un bloque de construcción fundamental del enfoque de Google para la gestión de servicios es la composición de cada equipo de SRE. En general, los SRE se pueden dividir en dos categorías principales.

50-60% son ingenieros de software de Google, o más precisamente, personas que han sido contratadas a través del procedimiento estándar para ingenieros de software de Google. El otro 40-50% son candidatos que estaban muy cerca de las calificaciones de ingeniería de software de Google (es decir, 85-99% del conjunto de habilidades requeridas), y que además tenían un conjunto de habilidades técnicas que es útil para SRE pero es raro para la mayoría de los ingenieros de software. Por lejos, los conocimientos de internos del sistema UNIX y la experiencia en redes (Capa 1 a Capa 3) son los dos tipos más comunes de habilidades técnicas alternativas que buscamos.

Común a todos los SRE es la creencia y la aptitud para desarrollar sistemas de software para resolver problemas complejos. Dentro de SRE, seguimos de cerca el progreso de carrera de ambos grupos, y hasta la fecha no hemos encontrado ninguna diferencia práctica en el rendimiento entre ingenieros de las dos vías. De hecho, el fondo diverso del equipo de SRE a menudo resulta en sistemas inteligentes y de alta calidad que son claramente el producto de la síntesis de varios conjuntos de habilidades.